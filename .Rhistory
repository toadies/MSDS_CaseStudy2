10^0.57539
10^0.43149
install.packages("glmnet")
#install.packages("Sleuth2", repos="http://R-Forge.R-project.org")
#install.packages('glmnet')
library(Sleuth3)
library(glmnet)
sat <- case1201
sat$ltakers <- log(sat$Takers)
head(sat)
sat.glmnet <- cv.glmnet(as.matrix(sat[-29,4:9]), sat[-29,2], alpha=0)
attributes(sat.glmnet)
##Optimal tuning parameter
best.lambda <- sat.glmnet$lambda.min
##Check parameter estimates for the optimal model
coef(sat.glmnet, s=best.lambda)
sat.glmnet2 <- cv.glmnet(as.matrix(sat[-29,4:9]), sat[-29,2], alpha=1)
##Optimal tuning parameter
best.lambda2 <- sat.glmnet2$lambda.min
##Check parameter estimates for the optimal model
coef(sat.glmnet2, s=best.lambda2)
#install.packages("caret")
library(caret)
tcontrol <- trainControl(method="repeatedcv", number=10, repeats=5)
sat.glmnet3 <- train(as.matrix(sat[-29,4:9]), sat[-29,2], trControl=tcontrol,
method="glmnet", tuneLength=10)
attributes(sat.glmnet3)
sat.glmnet3$results
##Note it actually says the lasso is best
sat.glmnet3$bestTune
sat.glmnet4 <- sat.glmnet3$finalModel
coef(sat.glmnet4, s=sat.glmnet3$bestTune$lambda)
lm.sat <- lm(SAT ~ Income + Years + Expend + Rank, data=sat[-29,])
ridge.pred <- predict(sat.glmnet, as.matrix(sat[-29,4:9]), s=best.lambda)
ridge.rmse <- sqrt(mean((ridge.pred - sat[-29,2])^2))
lasso.pred <- predict(sat.glmnet2, as.matrix(sat[-29,4:9]), s=best.lambda2)
lasso.rmse <- sqrt(mean((lasso.pred - sat[-29,2])^2))
en.pred <- predict(sat.glmnet4, as.matrix(sat[-29,4:9]), s=sat.glmnet3$bestTune$lambda)
en.rmse <- sqrt(mean((en.pred - sat[-29,2])^2))
stepwise.pred <- predict(lm.sat, sat[-29,4:9])
stepwise.rmse <- sqrt(mean((stepwise.pred - sat[-29,2])^2))
ridge.rmse
lasso.rmse
en.rmse
stepwise.rmse
confusionMatrix(data=user.rating.prediction.round, reference=user.rating.reference, positive='yes')
# Read the data
master.user.profile <- read.csv("C:/SMU/Courses/MSDS 6306 - DoingDataScience/github/MSDS_CaseStudy2/data/MasterUserProfile.csv")
# Subset random 80% of the observations for training, only the columns that we use as Predictors and the remaining observations for test
train.user.profile <- master.user.profile[sample(nrow(master.user.profile), nrow(master.user.profile) * 0.8), c(1:39,45)]
test.user.profile <- master.user.profile[!(master.user.profile$CheckinId %in% train.user.profile$CheckinId), c(1:39,45)]
# Load couple of libraries for Random Forest Model
library(randomForest)
library(h2o)
# First get a model using the randomForest library
# -  ERROR 1: Can not handle categorical predictors with more than 53 categories.
#             - IBU has 102 categories, ABV has 115 categories - IBU is Numeric but the problem may be with ABV which is a factor. Try converting
#               to numeric? - Easy to change in Excel - Seem to have worked!!!
#
user.profile.rf <- randomForest(train.user.profile[,-c(1,40)], train.user.profile[,40])
# Get some details about the model
user.profile.rf
user.profile.rf$importance
plot(user.profile.rf)
# Let's do some prediction for the test data
user.rating.prediction <- round(predict(user.profile.rf, test.user.profile[,-c(1,40)]), 2)
# How good did we do? Evaluate the results
library(pROC)
library(ggplot2)
library(reshape2)
library(caret)
user.rating.reference <-  as.factor(test.user.profile[,40])
# Confusion Matrix
confusionMatrix(data=as.factor(user.rating.prediction), as.factor(user.rating.reference), positive='yes')
# Let's round and see
user.rating.prediction.round <- as.factor(round(user.rating.prediction/0.25) * 0.25)
confusionMatrix(data=user.rating.prediction.round, reference=user.rating.reference, positive='yes')
levels(user.rating.prediction.round) <- seq(1,5,0.25)
levels(user.rating.reference) <- seq(1,5,0.25)
confusionMatrix(data=user.rating.prediction.round, reference=user.rating.reference, positive='yes')
plot(user.profile.rf$importance)
plot(sort(user.profile.rf$importance))
sort(user.profile.rf$importance)
user.profile.rf$importance
class(user.profile.rf$importance)
as.data.frame(user.profile.rf$importance)
80^2
# Read the data
master.user.profile <- read.csv("C:/SMU/Courses/MSDS 6306 - DoingDataScience/github/MSDS_CaseStudy2/data/MasterUserProfile.csv")
# Subset random 80% of the observations for training, only the columns that we use as Predictors and the remaining observations for test
train.user.profile <- master.user.profile[sample(nrow(master.user.profile), nrow(master.user.profile) * 0.8), c(1:39,45)]
test.user.profile <- master.user.profile[!(master.user.profile$CheckinId %in% train.user.profile$CheckinId), c(1:39,45)]
# Load couple of libraries for Random Forest Model
library(randomForest)
library(h2o)
# First get a model using the randomForest library
# -  ERROR 1: Can not handle categorical predictors with more than 53 categories.
#             - IBU has 102 categories, ABV has 115 categories - IBU is Numeric but the problem may be with ABV which is a factor. Try converting
#               to numeric? - Easy to change in Excel - Seem to have worked!!!
#
user.profile.rf <- randomForest(train.user.profile[,-c(1,40)], train.user.profile[,40])
# Get some details about the model
user.profile.rf
user.profile.rf$importance
plot(user.profile.rf)
plot(sort(user.profile.rf$importance))
# Let's do some prediction for the test data
user.rating.prediction <- round(predict(user.profile.rf, test.user.profile[,-c(1,40)]), 2)
# How good did we do? Evaluate the results
library(pROC)
library(ggplot2)
library(reshape2)
library(caret)
user.rating.reference <-  as.factor(test.user.profile[,40])
# Confusion Matrix
confusionMatrix(data=as.factor(user.rating.prediction), as.factor(user.rating.reference), positive='yes')
# Let's round and see
user.rating.prediction.round <- as.factor(round(user.rating.prediction/0.25) * 0.25)
confusionMatrix(data=user.rating.prediction.round, reference=user.rating.reference, positive='yes')
levels(user.rating.prediction.round) <- seq(1,5,0.25)
levels(user.rating.reference) <- seq(1,5,0.25)
confusionMatrix(data=user.rating.prediction.round, reference=user.rating.reference, positive='yes')
user.profile.rf$importance
install.packages("recommenderlab")
install.packages("sqldf")
library("recommenderlab")
library("sqldf")
setwd("C:/SMU/Courses/MSDS 6306 - DoingDataScience/github/MSDS_CaseStudy2/")
masterCheckIn <- read.csv("data/MasterUserProfile.csv")
beerCheckInData <- data.frame(sqldf("select UserName,beerId,BeerRating,beerName
from masterCheckIn"))
nrow(beerCheckInData)
head(beerCheckInData)
str(beerCheckInData)
summary(beerCheckInData)
beerReviewCount <- beerCheckInData %>% group_by(BeerId) %>% summarise(totalBeerReviews=n())
library(dplyr)
beerReviewCount <- beerCheckInData %>% group_by(BeerId) %>% summarise(totalBeerReviews=n())
beerReviewCount[with(beerReviewCount, order(totalBeerReviews,decreasing = TRUE)), ]
reviewFrequency<-beerReviewCount %>% group_by(totalBeerReviews) %>% summarise(reviewOccurance=n())
head(reviewFrequency,25)
beerReviewCntsubset<-subset(beerReviewCount,beerReviewCount$totalBeerReviews>5)
beerReviewCntsubset
ggplot(beerReviewCntsubset,aes(x=totalBeerReviews)) + geom_bar()
#Important User
userReviewsCount<- beerCheckInData %>% group_by(UserName) %>% summarise(totalUserReviews=n())
tail(userReviewsCount,10)
userReviewsCountSubset<-subset(userReviewsCount,userReviewsCount$totalUserReviews>=100)
ggplot(userReviewsCountSubset,aes(x=totalUserReviews)) + geom_bar()
significantBeers<-merge(beerCheckInData,beerReviewCntsubset,by.x="BeerId",by.y="BeerId")
significantBeers<-merge(significantBeers,userReviewsCountSubset,by.x="UserName",by.y="UserName")
summary(significantBeers)
head(significantBeers,5)
head(beersRealRatingmatrix)
beersRealRatingmatrix <- as(significantBeers[,c(1,2,3)], "realRatingMatrix")
class(beersRealRatingmatrix)
head(rowCounts(beersRealRatingmatrix))
head(colCounts(beersRealRatingmatrix))
head(rowMeans(beersRealRatingmatrix))
head(beersRealRatingmatrix)
# Read the data
master.user.profile <- read.csv("C:/SMU/Courses/MSDS 6306 - DoingDataScience/github/MSDS_CaseStudy2/data/MasterUserProfile.csv")
# Subset random 80% of the observations for training, only the columns that we use as Predictors and the remaining observations for test
train.user.profile <- master.user.profile[sample(nrow(master.user.profile), nrow(master.user.profile) * 0.8), c(1:39,45)]
test.user.profile <- master.user.profile[!(master.user.profile$CheckinId %in% train.user.profile$CheckinId), c(1:39,45)]
# Load couple of libraries for Random Forest Model
library(randomForest)
library(h2o)
# First get a model using the randomForest library
# -  ERROR 1: Can not handle categorical predictors with more than 53 categories.
#             - IBU has 102 categories, ABV has 115 categories - IBU is Numeric but the problem may be with ABV which is a factor. Try converting
#               to numeric? - Easy to change in Excel - Seem to have worked!!!
#
user.profile.rf <- randomForest(train.user.profile[,-c(1,40)], train.user.profile[,40])
# Get some details about the model
user.profile.rf
# How good did we do? Evaluate the results
library(pROC)
library(ggplot2)
library(reshape2)
library(caret)
user.rating.reference <-  as.factor(test.user.profile[,40])
# Confusion Matrix
confusionMatrix(data=as.factor(user.rating.prediction), as.factor(user.rating.reference), positive='yes')
# Let's round and see
user.rating.prediction.round <- as.factor(round(user.rating.prediction/0.25) * 0.25)
head(test.user.profile)
# Let's do some prediction for the test data
user.rating.prediction <- round(predict(user.profile.rf, test.user.profile[,-c(1,40)]), 2)
user.rating.prediction
plot(user.rating.prediction, test.user.profile[40])
class(user.rating.prediction)
plot(as.list(user.rating.prediction), test.user.profile[40])
class(test.user.profile[40])
test.user.profile[40]
plot(as.data.frame(user.rating.prediction), test.user.profile[40])
as.data.frame(user.rating.prediction)
test.user.profile[40]
plot(as.list(user.rating.prediction), as.list(test.user.profile[40])
)
as.data.frame(user.rating.prediction) - test.user.profile[40]
mean(as.data.frame(user.rating.prediction) - test.user.profile[40])
as.data.frame(user.rating.prediction) - test.user.profile[40]
class(as.data.frame(user.rating.prediction) - test.user.profile[40])
mean(as.list(as.data.frame(user.rating.prediction) - test.user.profile[40]))
sum(as.list(as.data.frame(user.rating.prediction) - test.user.profile[40]))
sum(as.data.frame(user.rating.prediction) - test.user.profile[40])
?mse
mse(test.user.profile[40], as.data.frame(user.rating.prediction)
)
library(ModelMetrics)
mse(test.user.profile[40], as.data.frame(user.rating.prediction))
mse(as.list(test.user.profile[40]), as.list(as.data.frame(user.rating.prediction)))
mean((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)[1]
as.data.frame(user.rating.prediction) - test.user.profile[40])^2
(as.data.frame(user.rating.prediction) - test.user.profile[40])^2
(as.data.frame(user.rating.prediction) - test.user.profile[40])
(as.data.frame(user.rating.prediction) - test.user.profile[40])^2
as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
mean(as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2))
mean(as.numeric(as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)))
as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
mean(as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2))
user.rating.prediction
mean((as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)))
as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
diffsquares <- as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
diffsquares
mean(diffsquares)
colMeans(diffsquares)
colMeans((as.list((as.data.frame(user.rating.prediction) - test.user.profile[40])^2)))
colMeans((as.data.frame(user.rating.prediction) - test.user.profile[40])^2))
colMeans(as.data.frame(user.rating.prediction) - test.user.profile[40])^2))
colMeans(as.data.frame(user.rating.prediction) - test.user.profile[40])^2)
colMeans(as.data.frame(user.rating.prediction) - test.user.profile[40])^2))
colMeans(as.data.frame(user.rating.prediction) - test.user.profile[40]))
colMeans(as.data.frame(user.rating.prediction) - test.user.profile[40])
plot(as.data.frame(user.rating.prediction), test.user.profile[40])
plot(as.list(as.data.frame(user.rating.prediction)), as.list(test.user.profile[40]))
sd(as.data.frame(user.rating.prediction) - test.user.profile[40])
test.user.profile[,40]
sd(as.data.frame(user.rating.prediction) - test.user.profile[,40])
sd(user.rating.prediction - test.user.profile[,40])
mean(user.rating.prediction - test.user.profile[,40])
plot(user.rating.prediction - test.user.profile[,40])
mean((user.rating.prediction - test.user.profile[,40])^2)
qqnorm((user.rating.prediction - test.user.profile[,40])/sd(user.rating.prediction - test.user.profile[,40]))
qqline((user.rating.prediction - test.user.profile[,40])/sd(user.rating.prediction - test.user.profile[,40]))
plot(test.user.profile[,40], user.rating.prediction)
names(train.user.profile)
# Second get a model using limited features
user.profile.rf <- randomForest(train.user.profile[,c(2, 3, 4, 38, 39)], train.user.profile[,40])
# Second get a model using limited features
user.profile.rf.2 <- randomForest(train.user.profile[,c(2, 3, 4, 38, 39)], train.user.profile[,40])
user.profile.rf2
user.profile.rf.2
# First get a model using the randomForest library
# -  ERROR 1: Can not handle categorical predictors with more than 53 categories.
#             - IBU has 102 categories, ABV has 115 categories - IBU is Numeric but the problem may be with ABV which is a factor. Try converting
#               to numeric? - Easy to change in Excel - Seem to have worked!!!
#
user.profile.rf <- randomForest(train.user.profile[,-c(1,40)], train.user.profile[,40])
# Get some details about the model
user.profile.rf
# Second get a model using limited features
user.profile.rf.2 <- randomForest(train.user.profile[,c(3, 4, 38, 39)], train.user.profile[,40])
user.profile.rf.2
# Second get a model using limited features
user.profile.rf.2 <- randomForest(train.user.profile[,c(2, 3, 4, 38, 39)], train.user.profile[,40])
user.profile.rf.2
user.profile.rf.2$importance
# Second get a model using limited features
user.profile.rf.2 <- randomForest(train.user.profile[,c(2, 38, 39)], train.user.profile[,40])
user.profile.rf.2
user.profile.rf.2$importance
user.profile.rf.3 <- randomForest(train.user.profile[,-c(1,40)], train.user.profile[,40]>=3.5)
user.profile.rf.3
user.profile.rf.3 <- randomForest(train.user.profile[,-c(1,40)], as.factor(train.user.profile[,40]>=3.5))
user.profile.rf.3
user.profile.rf.2 <- randomForest(train.user.profile[,-c(1,40)], as.factor(train.user.profile[,40]>=3.5))
user.profile.rf.2
# Second get a model using limited features
user.profile.rf.3 <- randomForest(train.user.profile[,c(2, 3, 4, 38, 39)], as.factor(train.user.profile[,40]>=3.5))
user.profile.rf.3
user.profile.rf.3$importance
user.profile.rf.2$importance
user.profile.rf
user.profile.rf.3
user.profile.rf.2
as.factor(train.user.profile[,40]>=3.5
)
user.rating.prediction.2 <- predict(user.profile.rf.2, test.user.profile[,-c(1,40)])
user.rating.prediction.2
user.rating.prediction.2 == as.factor(train.user.profile[,40]>=3.5)
length(which(user.rating.prediction.2 == as.factor(train.user.profile[,40]>=3.5)))
count(test.user.profile)
user.rating.prediction.2 <- predict(user.profile.rf.2, test.user.profile[,-c(1,40)])
user.rating.prediction.2
nrow(test.user.profile)
nrow(user.rating.prediction)
user.rating.prediction
user.rating.prediction <- round(predict(user.profile.rf, train.user.profile[,-c(1,40)]), 2)
plot(test.user.profile[,40], user.rating.prediction)
plot(train.user.profile[,40], user.rating.prediction)
# Let's round and see
user.rating.prediction.round <- as.factor(round(user.rating.prediction/0.25) * 0.25)
plot(train.user.profile[,40], user.rating.prediction.round)
user.rating.prediction.round
train.user.profile[,40]
user.profile.rf.3
user.profile.rf.2
user.profile.rf
user.profile.rf.2
# Second get a model using limited features
user.profile.rf.2 <- randomForest(train.user.profile[,c(2, 3, 4, 38, 39)], as.factor(train.user.profile[,40]>=3.5))
user.profile.rf.2
library("recommenderlab")
library("sqldf")
library(dplyr)
setwd("C:/Users/Anand/Documents/SMU/DDS/GITHUB/Case-Study-2/MSDS_CaseStudy2/")
setwd("C:/SMU/Courses/MSDS 6306 - DoingDataScience/github/MSDS_CaseStudy2/")
masterCheckIn <- read.csv("data/MasterUserProfile.csv")
masterCheckIn <- read.csv("data/MasterUserProfile.csv")
beerCheckInData <- data.frame(sqldf("select UserName,beerId,BeerRating,beerName from masterCheckIn"))
nrow(beerCheckInData)
head(beerCheckInData)
str(beerCheckInData)
summary(beerCheckInData)
beerReviewCount <- beerCheckInData %>% group_by(BeerId) %>% summarise(totalBeerReviews=n())
beerReviewCount[with(beerReviewCount, order(totalBeerReviews,decreasing = TRUE)), ]
reviewFrequency<-beerReviewCount %>% group_by(totalBeerReviews) %>% summarise(reviewOccurance=n())
head(reviewFrequency,25)
beerReviewCntsubset<-subset(beerReviewCount,beerReviewCount$totalBeerReviews>5)
beerReviewCntsubset
#Important User
userReviewsCount<- beerCheckInData %>% group_by(UserName) %>% summarise(totalUserReviews=n())
tail(userReviewsCount,10)
userReviewsCountSubset<-subset(userReviewsCount,userReviewsCount$totalUserReviews>=100)
significantBeers<-merge(beerCheckInData,beerReviewCntsubset,by.x="BeerId",by.y="BeerId")
significantBeers<-merge(significantBeers,userReviewsCountSubset,by.x="UserName",by.y="UserName")
summary(significantBeers)
head(significantBeers,5)
beersRealRatingmatrix <- as(significantBeers[,c(1,2,3)], "realRatingMatrix")
class(beersRealRatingmatrix)
head(rowCounts(beersRealRatingmatrix))
head(colCounts(beersRealRatingmatrix))
-0.648^2
(-0.648)^2
